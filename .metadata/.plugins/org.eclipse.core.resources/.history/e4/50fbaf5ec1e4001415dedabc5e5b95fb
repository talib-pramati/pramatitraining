package processcrawling;

import java.util.HashSet;
import java.util.LinkedList;
import java.util.Queue;
import java.util.Set;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;

public class WebCrawler implements WebCrwalerInterface{
	
	private final Set<String> visitedLinks= new HashSet<String>();
	private  Queue<String> queue = new LinkedList<String>();
	private ExecutorService executor;
	private String url;
	
	
	public WebCrawler(String startingURL, int maximum_threads)
	{
		this.url = startingURL;
		executor = Executors.newFixedThreadPool(maximum_threads);
		
	}
	
	public void startCrawling(String url)
	{
		startNewThread(url);
	}
	
	
	
	@Override
	public void enqueURL(String url) {
		// TODO Auto-generated method stub
		
	}
	
	public void startNewThread(String url)
	{
		
		executor.execute(new LinkExtractor(url,this));
	}

	@Override
	public void addVisitedLinks(String url) {
		
		visitedLinks.add(url);
	}

	@Override
	public Boolean isContainsURL(String url) {
		// TODO Auto-generated method stub
		return visitedLinks.contains(url);
	}
	
	public Set<String> getVisitedLinks()
	{
		return this.visitedLinks;
	}

	

}
